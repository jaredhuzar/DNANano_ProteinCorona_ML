{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77209aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from scipy import stats\n",
    "import imblearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay, auc\n",
    "\n",
    "inputDir = 'AnalyzedData\\\\'\n",
    "outputDir = 'Results\\\\'\n",
    "\n",
    "inputFile=sys.argv[0]\n",
    "\n",
    "dataPresent = pd.read_csv(inputFile)\n",
    "abundance_present = dataPresent['Present']\n",
    "abundance_present = np.asarray(abundance_present)\n",
    "dataPresent.drop(['Present', 'Protein', 'Sample', 'Unnamed: 0'],inplace = True, axis =1)\n",
    "\n",
    "\n",
    "\n",
    "def train_run_model(xData,yData, label1):\n",
    "    classifier = xgb.XGBClassifier()\n",
    "    data = xData\n",
    "    Y = yData\n",
    "\n",
    "    clf = classifier\n",
    "    scores = list()\n",
    "    features = list()\n",
    "    acc=list()\n",
    "    prec=list()\n",
    "    rec = list()\n",
    "    aucScores = list()\n",
    "    b = 0\n",
    "    kFold=KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "    for train_index,test_index in kFold.split(data):\n",
    "        X_train, X_test, y_train, y_test = data.loc[train_index], data.loc[test_index], Y[train_index], Y[test_index]\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        #scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        scores.append(metrics.f1_score(y_test, y_pred))\n",
    "        acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        features.append(clf.feature_importances_)\n",
    "        prec.append(metrics.precision_score(y_test, y_pred))\n",
    "        rec.append(metrics.recall_score(y_test, y_pred))\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        aucScores.append(roc_auc_score(y_test,y_pred[:,1]))\n",
    "        if(b == 0):\n",
    "            fets = pd.DataFrame(clf.feature_importances_)\n",
    "        else:\n",
    "            fets=pd.concat([fets,pd.DataFrame(clf.feature_importances_)], ignore_index = True, axis = 1)\n",
    "        b=b+1\n",
    "        \n",
    "    allmet=pd.DataFrame({'AUC':aucScores,'F1':scores, 'Accuracy':acc, 'Recall':rec, 'Precision':prec})\n",
    "    allmet['DataSet'] = label1\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    plt.rc('font', family='serif')\n",
    "    plt.rc('font', family='serif')\n",
    "    #plt.rc('xtick', labelsize='large')\n",
    "    #plt.rc('ytick', labelsize='large')\n",
    "\n",
    "    vals = list()\n",
    "    metricname  = list()\n",
    "    DataSet = list()\n",
    "    for i in allmet.columns[0:5]:\n",
    "        vals1=allmet[i]\n",
    "        for z in range(len(vals1)):\n",
    "            DataSet.append(allmet.loc[z,'DataSet'])\n",
    "            vals.append(vals1[z])\n",
    "            metricname.append(i)\n",
    "    everymet=pd.DataFrame({'Scores':vals, 'Metric':metricname, 'Model':DataSet})\n",
    "\n",
    "    met = allmet\n",
    "    labs=[\"{:.2f}\".format(np.mean(met['AUC'])),\"{:.2f}\".format(np.mean(met['F1'])),\"{:.2f}\".format(np.mean(met['Accuracy'])),\"{:.2f}\".format(np.mean(met['Recall'])),\"{:.2f}\".format(np.mean(met['Precision']))]\n",
    "    fig, ax = plt.subplots()\n",
    "    g=sns.barplot(data = everymet,x='Metric', y = 'Scores',palette='colorblind', saturation = .7)\n",
    "    ax.set_ylim(0, 1)\n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i,labels = labs,padding=-30)\n",
    "    #plt.title('All Information Enriched vs Not Enriched')\n",
    "    g.set(ylim=(0, 1), xlabel =\"Metrics\", ylabel = \"Scores\", title ='Model Performance')\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.savefig(outputDir + 'PresentPerformance.png', bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    explainer = shap.Explainer(clf, data)\n",
    "    shap_values = explainer.shap_values(data)\n",
    "    shap.summary_plot(shap_values, data.astype(\"float\"))\n",
    "    plt.savefig(outputDir + 'ShapPresent.png', bbox_inches = 'tight')\n",
    "    \n",
    "    clf = classifier\n",
    "    scores = list()\n",
    "    features = list()\n",
    "    acc=list()\n",
    "    cv=KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "    y=np.asarray(yData)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    n_splits=10\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    for fold, (train, test) in enumerate(cv.split(data, y)):\n",
    "        classifier.fit(data.loc[train], y[train])\n",
    "        viz = RocCurveDisplay.from_estimator(\n",
    "            classifier,\n",
    "            data.loc[test],\n",
    "            y[test],\n",
    "            name=f\"ROC fold {fold+1}\",\n",
    "            alpha=0.3,\n",
    "            lw=1,\n",
    "            ax=ax,\n",
    "            #plot_chance_level=(fold == n_splits - 1),\n",
    "        )\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Mean ROC curve with variability Present Protein Prediction\",\n",
    "    )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    #plt.show()\n",
    "    plt.savefig(outputDir + 'PresentAUC.png',bbox_inches='tight')\n",
    "    return [everymet,fets,shap_values]\n",
    "\n",
    "def getFeatureImportances(featureImportance, data):\n",
    "    medianFeatures=featureImportance.median(axis =1)\n",
    "    retFeatures=pd.DataFrame(medianFeatures)\n",
    "    retFeatures.index = data.columns\n",
    "    return retFeatures\n",
    "\n",
    "statsPres,featureImportancePres,shapsPres =train_run_model(dataPresent,abundance_present,'Present')\n",
    "\n",
    "presentImportance=getFeatureImportances(featureImportancePres,dataPresent)\n",
    "\n",
    "presentImportance.to_csv(outputDir + 'PresentFeatureImportance.csv')\n",
    "statsPres.to_csv(outputDir + 'PresentStats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
