{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26520b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from scipy import stats\n",
    "import imblearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay, auc\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale = 2)\n",
    "\n",
    "outputDir = 'Results\\\\'\n",
    "\n",
    "inputFile=sys.argv[1]\n",
    "\n",
    "dataPresent = pd.read_csv(inputFile)\n",
    "abundance_present = dataPresent['Present']\n",
    "abundance_present = np.asarray(abundance_present)\n",
    "dataPresent.drop(['Present', 'Protein', 'Sample', 'Unnamed: 0'],inplace = True, axis =1)\n",
    "\n",
    "classifier = xgb.XGBClassifier()\n",
    "\n",
    "Y = np.asarray(abundance_binary)\n",
    "\n",
    "clf = classifier\n",
    "scores = list()\n",
    "features = list()\n",
    "acc=list()\n",
    "prec=list()\n",
    "rec = list()\n",
    "aucScores=list()\n",
    "kFold=KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "for train_index,test_index in kFold.split(dataNew):\n",
    "    X_train, X_test, y_train, y_test = dataNew.loc[train_index], dataNew.loc[test_index], Y[train_index], Y[test_index]\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    scores.append(metrics.f1_score(y_test, y_pred))\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    features.append(clf.feature_importances_)\n",
    "    prec.append(metrics.precision_score(y_test, y_pred))\n",
    "    rec.append(metrics.recall_score(y_test, y_pred))\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    aucScores.append(roc_auc_score(y_test,y_pred[:,1]))\n",
    "\n",
    "allmet=pd.DataFrame({'AUC':aucScores,'F1':scores, 'Accuracy':acc, 'Recall':rec, 'Precision':prec})\n",
    "allmet['Model'] = 'XGBoost'\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "clf = classifier\n",
    "scores = list()\n",
    "features = list()\n",
    "acc=list()\n",
    "prec=list()\n",
    "rec = list()\n",
    "aucScores=list()\n",
    "kFold=KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "for train_index,test_index in kFold.split(dataNew):\n",
    "    X_train, X_test, y_train, y_test = dataNew.loc[train_index], dataNew.loc[test_index], Y[train_index], Y[test_index]\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    scores.append(metrics.f1_score(y_test, y_pred))\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    features.append(clf.feature_importances_)\n",
    "    prec.append(metrics.precision_score(y_test, y_pred))\n",
    "    rec.append(metrics.recall_score(y_test, y_pred))\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    aucScores.append(roc_auc_score(y_test,y_pred[:,1]))\n",
    "\n",
    "rfMet=pd.DataFrame({'AUC':aucScores,'F1':scores, 'Accuracy':acc, 'Recall':rec, 'Precision':prec})\n",
    "rfMet['Model'] = 'Random Forest'\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "clf = classifier\n",
    "scores = list()\n",
    "features = list()\n",
    "acc=list()\n",
    "prec=list()\n",
    "rec = list()\n",
    "aucScores=list()\n",
    "kFold=KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "for train_index,test_index in kFold.split(dataNew):\n",
    "    X_train, X_test, y_train, y_test = dataNew.loc[train_index], dataNew.loc[test_index], Y[train_index], Y[test_index]\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    scores.append(metrics.f1_score(y_test, y_pred))\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    features.append(clf.feature_importances_)\n",
    "    prec.append(metrics.precision_score(y_test, y_pred))\n",
    "    rec.append(metrics.recall_score(y_test, y_pred))\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    aucScores.append(roc_auc_score(y_test,y_pred[:,1]))\n",
    "\n",
    "gradientMet=pd.DataFrame({'AUC':aucScores,'F1':scores, 'Accuracy':acc, 'Recall':rec, 'Precision':prec})\n",
    "gradientMet['Model'] = 'Gradient Boosting'\n",
    "\n",
    "metricComparison = pd.concat([allmet, rfMet, gradientMet])\n",
    "metricComparison.reset_index(drop=True, inplace = True)\n",
    "\n",
    "vals = list()\n",
    "metricname  = list()\n",
    "DataSet = list()\n",
    "for i in metricComparison.columns[0:5]:\n",
    "    vals1=metricComparison[i]\n",
    "    for z in range(len(vals1)):\n",
    "        DataSet.append(metricComparison.loc[z,'Model'])\n",
    "        vals.append(vals1[z])\n",
    "        metricname.append(i)\n",
    "everymet=pd.DataFrame({'Scores':vals, 'Metric':metricname, 'Model':DataSet})\n",
    "\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize='large')\n",
    "plt.rc('ytick', labelsize='large')\n",
    "g = sns.catplot(\n",
    "    data=everymet, kind=\"bar\",\n",
    "    x=\"Model\", y=\"Scores\", hue=\"Metric\",\n",
    "    palette='colorblind', alpha=.6, height=6,saturation = .7\n",
    ")\n",
    "#g.despine(left=True)\n",
    "g.set(ylim=(0, 1), title='Performance Across Models')\n",
    "g.set_axis_labels(\"\", \"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "g.legend.set_title(\"\")\n",
    "plt.savefig(outputDir + 'comparingModels.png',bbox_inches='tight')\n",
    "everymet.to_csv(outputDir + 'ModelComparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
